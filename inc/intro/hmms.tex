\label{sec:hmms}
Hidden Markov models (HMMs) are probabilistic models that are generally
applicable to ``linear'' problems and have been widely used in speech
recognition algorithms for thirty years. 

HMMs were introduced into computational biology by \cite{churchill1989} and
used as profile models since the 1990s (\cite{krogh1994}).

to time series or linear sequences.  This property makes them very useful for
application on biological sequences.

Proteins, RNAs and other biological molecular sequences can usually be
classified into families of related sequences and structures
(\cite{henikoff1997}).

In contrast to a sequence similarity-based search tool like BLAST,
Needleman-Wunsch (\cite{needleman1970}) or Smith-Waterman (\cite{smith1981}),
HMM-based alignment algorithms search for homology. 

\begin{figure}[h]
	\begin{center}
		\def\svgwidth{\textwidth}
		\input{img/hmm-eddy.pdf_tex}
	\end{center}
	\caption[A simple hidden Markov model]{A simple, two-state hidden Markov model
		describing a DNA sequence with a heterogenous base composition. 
		\begin{inparaenum}[\textbf{a)}]
			\item State 1 generates AT-rich sequences. State 2 generates CG-rich
				sequences (so-called CpG islands). State transitions and their respective
				probabilities are indicated by arrows. Symbol emission probabilities for
				each state are listed below the states.
			\item At each position, the model not only emits a symbol with a
				probability that is dependent on its state, it also transits to the
				other state with a certain probability, or remains in the present state.
			\item The symbol sequence is the result of of the state transitions and
				the emission probabilities in that state.
		\end{inparaenum}
	}
	\label{fig:hmm}
\end{figure}
